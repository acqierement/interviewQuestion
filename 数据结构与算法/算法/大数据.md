# 大数据

## 100亿个标题中搜索到想要的关键字标题。

## 从1到n一共n个数，找出和为m的所有数的和，我说出了高斯的方法，，他问万一是大数据呢，很多很多数据呢。

## 十万的数字中找出前100？

说了快排patition+二分，堆

## 10亿的数字找前10万，空间给1亿

分治法加堆,分析时间复杂度

## 100亿数字找前10亿，空间1亿

bitmap?

## 你找到第300个大的正整数

本地文件abc.txt，里面存放了5000万个正整数，每一行一个正整数，正整数取值范围为1-5000万，现要求你找到第300个大的正整数？要求时间复杂度为O(1)



## 查找大量数据里是否存在某一数据

优化高效的办法?

提示我了list和set

> 大数据面试题——如何在大量数据中判断一个数是否存在 - CircleYuan的博客 - CSDN博客
> https://blog.csdn.net/kingyuan666/article/details/84583980  
>
> 方法一：分治法
>
> 对于大数据相关的算法题，分治法是一个非常好的方法。针对这一题来说，主要思路为：可以根据实际可用内存的情况，确定一个Hash函数，比如：hash(value)%1000，通过这个Hash函数可以把这2.5亿个数字划分到1000个文件中去（a1，a2……，a1000），然后再对待查找的数字使用同样的Hash函数求出Hash值，假设计算出的Hash值为i，如果这个数存在，那么它一定在文件ai中。通过这种方法就可以把题目转化为文件ai中是否存在这个数。那么接下来的求解过程中可以选用的思路计较多，有：
>
> （1）由于划分后的文件比较小了，就可以直接装载到内存中去，可以把文件中所有的数字都保存到hash_set中，然后判断待查找的数字是否存在。
>
> （2）如果这个文件中的数字占用的空间还是太大，那么可以用1相同的方法把这个文件继续划分为更小的文件，然后确定待查找的数字可能存在的文件，然后在相应的文件中继续查找。

## 海量字符串数据查询次数出现次数最多的字符串，海量是指根本存不下去

一次处理根本不能处理，所以分机器处理。

假设有M太机器,求出每个字符串的字符串Hash值模M的值分配到对应的机器上,对每个机器上的字符串分别求出现次数最多的字符串(使用Map记录就可以),在取M台机器中出现次数最多的。这是我之前学习海量数据处理时经常看到的方法

## 给1亿个数字，如何取到top k的数字

一亿个数字可以在单机完成吗？怎样提升效率